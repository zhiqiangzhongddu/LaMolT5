# VLLM
This is a generic framework for using different LLMS. If you want to use a different LLM than gemini or chatGPT, like mistral or llama. They can be configured in the ```vllm_prompt``` file.